% !TEX root = ../coursera_sc_01.tex

\begin{frame} % название фрагмента

    \videotitle{Conditional expectation}
    
\end{frame}
    
    
\begin{frame}{Conditional expectation: short plan}
    
      \begin{itemize}[<+->]
        \item Modeling information using \alert{sigma-algebras};
        \item \alert{Properties} of conditional expected value;
        \item Conditional \alert{variance}.
      \end{itemize}
    
\end{frame}
    
    
\begin{frame}{Modeling information}
    
    \onslide<2->{John knows the value of $X$.}

    \onslide<3->{Maria knows the value of $X$ and $Y$.}

    \onslide<4->{Maria knows \alert{more}!}

    \onslide<5->{How to model this \alert{mathematically?}}
    
\end{frame}



\begin{frame}
    \frametitle{Sigma-algebra}

    \pause
    \begin{block}{Informal definition \informalduck}
        \alert{Sigma-algebra} ($\sigma$-algebra) generated by random variables $X$ and $Y$ is the collection 
        of all events that can be stated in terms of these random variables. 
        
        \pause
        Notation: $\sigma(X, Y)$.
    \end{block}

    \pause
    \begin{block}{Example}
    The sigma-algebra $\sigma(X, Y)$ contains the events $\{X < 5\}$, $\{X > 2Y\}$, $\{\sin Y > \cos X\}$, \ldots
    \end{block}    

\end{frame}


\begin{frame}{Modeling information}
    
    \onslide<2->{John knows the value of $X$, $\cF_J =\sigma (X)$.}

    \onslide<3->{Maria knows the value of $X$ and $Y$, $\cF_M = \sigma (X, Y)$}

    \onslide<4->{Maria knows \alert{more}: $\cF_J \subset \cF_M$.}
    
\end{frame}



\begin{frame}
    \frametitle{Measurability}

    \pause
    \begin{block}{Definition \formalduck}
        The random variable $R$ is measurable with respect to $\sigma$-algebra $\cF$ if 
        $\sigma(R) \subset \cF$. 
    \end{block}
    \pause
    Information in $\cF$ is sufficient to calculate the value of $R$.
    \pause
    \begin{block}{Informal theorem \informalduck}
        The random variable $R$ is measurable with respect to $\sigma(X, Y)$ if and only if
        $R$ is a deterministic function of $X$ and $Y$.  
    \end{block}
\end{frame}


\begin{frame}
    \frametitle{Best prediction}

    \begin{block}{Informal definition \informalduck}
        The \alert{best prediction} of a random variable $R$ given $\sigma$-algebra $\cF$ is called 
        \alert{conditional expected value} $\E(R \mid \cF)$.
    \end{block}

    \pause 
    \begin{block}{Difference of $\E(R \mid \cF)$ and $\E(R)$}
    If I know $X$ and $Y$ then my best prediction of $R$ may depend on $X$ and $Y$.

    In general: $\E(R \mid \cF)$ is a \alert{random variable}.
    \end{block}
\end{frame}


\begin{frame}
    \frametitle{Notation}

    \begin{itemize}[<+->]
        \item $\alert{\E(R \mid \cF)}$: 
        
        for a general $\sigma$-algebra $\cF$;
        \item $\E(R \mid \sigma(X, Y))$ or $\alert{\E(R \mid X, Y)}$: 
        
        for $\sigma$-algebra generated by $X$ and $Y$.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{When we may omit conditioning?}

    \begin{itemize}[<+->]

        \item If $R$ is \alert{independend} of $X$ and $Y$ then $\E(R \mid X, Y) = \E(R)$:

        If I know \alert{nothing useful} about $R$ then I can drop my information. 

        \item $\E( \E( R \mid \cF) ) = \E(R)$:
        
        The \alert{average of best guess} is the average of predicted variable. 

    \end{itemize}

\end{frame}




\begin{frame}
    \frametitle{The case of known variable}

    If $R$ is \alert{known} (measurable with respect to $\cF$), 
    then we may treat $R$ \textit{like} a constant:

    \[
        \onslide<2->{\E(R \mid \cF ) = R;}
    \]
    \[
        \onslide<3->{\E(2\exp(5W_t) \mid W_t) = 2\exp(5W_t);}
    \]
    \[
        \onslide<4->{\E(2R S + R^2 \mid \cF ) = 2R \E(S\mid \cF) + R^2.}
    \]


\end{frame}


\begin{frame}
    \frametitle{Conditional variance}

    \begin{block}{Definition \formalduck}
        The \alert{conditional variance} $\Var(R \mid \cF)$ is the conditional expected value of the 
        squared error of the best prediction,
        \pause
        \[
            \Var(R \mid \cF) = \E(\Delta^2 \mid \cF), \text{ where } \Delta = R - \E(R \mid \cF).
        \]
    \end{block}

    \pause 
    \begin{block}{Theorem \formalduck}
        \[
            \Var(R \mid \cF) = \E(R^2 \mid \cF) - (\E(R \mid \cF) )^2.
        \]
    \end{block}
\end{frame}




\begin{frame}
    \frametitle{Properties of conditional variance}

    \begin{itemize}[<+->]
        \item Irrelevant information may be omitted:
        
        If $R$ is \alert{independent} of $\cF$ then $\E(R \mid \cF) = \E(R)$ and $\Var(R \mid \cF) = \Var(R)$.
        

        \item If $R$ is \alert{known} (measurable with respect to $\cF$), 
        then we may treat $R$ \textit{like} a constant:
        \[
            \onslide<3->{\Var(2\exp(5W_t) \mid W_t) = 0;}
        \]
        \[
            \onslide<4->{\Var(2R S + R^2 \mid \cF ) = (2R)^2\Var(S \mid \cF) + 0.}
        \]
            
    \end{itemize}


\end{frame}


    \begin{frame}{Conditioning: summary}
    
    \begin{itemize}[<+->]
        \item Sigma-algebra $\sigma(X, Y)$ is the collection of all events that \alert{can be stated} using $X$ and $Y$.
        \item Conditional expected value $\E(R \mid X, Y)$ is the \alert{best prediction} of $R$ using $X$ and $Y$.
        \item Conditional variance $\Var(R \mid X, Y)$ is the conditional expected value of the \alert{squared error} of the best prediction.
    \end{itemize}
      
    \end{frame}
    